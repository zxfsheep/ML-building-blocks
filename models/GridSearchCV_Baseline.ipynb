{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zoo of common baseline models. These usually will not produce the best prediction, but they are fast (orders of magnitude faster than more complicated models).\n",
    "In my opinion, they are useful for:\n",
    "* Getting a quick baseline result for the problem, which serves as a sanity check.\n",
    "* Can throw in a small portion into the final result, which is somewhat a final regularization.\n",
    "* Help to find a good KFold split for expensive models, as will be explained in my random-idea repository.\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col = 0)\n",
    "cols = list(train.columns)\n",
    "cols.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train[cols])\n",
    "train_aft = scaler.transform(train[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear regression\n",
    "  * Technically there is nothing to gridsearch for. But Scikit-learn's GridSearchCV provides a very convenient dict format output, so I use it as a wrapper anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "params = {}\n",
    "gs = GridSearchCV(lr, params, scoring = 'neg_mean_squared_error', cv = kf, return_train_score = False)\n",
    "gs.fit(train_aft, train['target'])\n",
    "pd.DataFrame(gs.cv_results_).to_csv('gridcv.csv')\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ridge regression\n",
    "  * The larger alpha is, the more l2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = Ridge(tol = 0.000001)\n",
    "params = {'alpha':[214]}\n",
    "gs = GridSearchCV(rd, params, scoring = 'neg_mean_squared_error', cv = kf, return_train_score = False)\n",
    "gs.fit(train_aft, train['target'])\n",
    "pd.DataFrame(gs.cv_results_).to_csv('gridcv.csv')\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lasso regression\n",
    "  * The larger alpha is, the more l1 regularization.\n",
    "  * This encourages sparser weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = Lasso(tol = 0.000001)\n",
    "params = {'alpha':[214]}\n",
    "gs = GridSearchCV(ls, params, scoring = 'neg_mean_squared_error', cv = kf, return_train_score = False)\n",
    "gs.fit(train_aft, train['target'])\n",
    "pd.DataFrame(gs.cv_results_).to_csv('gridcv.csv')\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ElasticNet\n",
    "  * The larger alpha is, the more regularization.\n",
    "  * l1_ratio is between 0 and 1, indicating how much regularization should come from l1 penalty. \n",
    "  * In other words, l2 penalty constitutes (1-l1_ratio) portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = ElasticNet(tol = 0.000001)\n",
    "\n",
    "params = {'alpha':[214], 'l1_ratio':[0.5]}\n",
    "gs = GridSearchCV(en, params, scoring = 'neg_mean_squared_error', cv = kf, return_train_score = False)\n",
    "gs.fit(train_aft, train['target'])\n",
    "pd.DataFrame(gs.cv_results_).to_csv('gridcv.csv')\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Support Vector Machine regression\n",
    "  * Opposite to alpha above, lower C leads to more regularization, and hence smoother boundaries\n",
    "  * gamma affects the influence radius of the kernel. The lower gamma is, the farther the kernel affects neighboring points, which lead to smoother boundaries\n",
    "  * epsilon is a tolerance term. If the error is within epsilon, it is ignored completely.\n",
    "  * If the data size is large, `svr` is slow because it is kernel-trick based. Consider `LinearSVR` which is not kernel-trick based but only supports linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr  = SVR(kernel = 'rbf',tol = 0.000001, cache_size = 2000)\n",
    "params = {'C':[0.1, 0.2, 0.3], 'gamma':[0.080], 'epsilon':[0.1]}\n",
    "gs = GridSearchCV(svr, params, scoring = 'neg_mean_squared_error', cv = kf, return_train_score = False, verbose = 1)\n",
    "gs.fit(train_after, train['target'])\n",
    "pd.DataFrame(gs.cv_results_).to_csv('gridcv.csv')\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = gs.best_estimator_\n",
    "et.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col = 0)\n",
    "test_aft = scaler.transform(test[cols])\n",
    "test['target'] = et.predict(test_aft)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 286.25,
   "position": {
    "height": "40px",
    "left": "1190px",
    "right": "15.6px",
    "top": "78px",
    "width": "330.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
