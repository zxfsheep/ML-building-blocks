{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a complete customized cross validation using XGBoost, which also produces the final prediction, feature importance, and training prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.ion()\n",
    "import xgboost as xgb\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(df, n_folds, params, stratified = True, save_train_prediction = False, n_estimators=10000):\n",
    "    \n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(f\"Starting XGBoost. Train shape: {train_df.shape}, test shape: {test_df.shape}\")\n",
    "\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 2018)\n",
    "    else:\n",
    "        folds = KFold(n_splits = n_folds, shuffle = True, random_state = 2018)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    prediction = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        print('Fold', n_fold, 'started at', time.ctime())\n",
    "        xgtrain = xgb.DMatrix(data = train_df[feats].iloc[train_idx], label=train_df['TARGET'].iloc[train_idx])\n",
    "        evalset = xgb.DMatrix(data = train_df[feats].iloc[valid_idx], label=train_df['TARGET'].iloc[valid_idx])\n",
    "        bst = xgb.train(params = params, dtrain = xgtrain, num_boost_round = n_estimators, early_stopping_rounds = 200, evals = [(evalset, 'try')], maximize = True,verbose_eval = 100)\n",
    "        del xgtrain\n",
    "        gc.collect()\n",
    "        \n",
    "        test_pred_proba[valid_idx] = bst.predict(evalset, ntree_limit = bst.best_iteration)\n",
    "        testinput = xgb.DMatrix(data = test_df[feats])\n",
    "        prediction += bst.predict(testinput, ntree_limit = bst.best_iteration) / folds.n_splits\n",
    "        \n",
    "        bst.get_score(fmap='Fold_' + n_fold +'_feature_importance.csv', importance_type='weight')\n",
    "        \n",
    "        print(f'Fold {n_fold:2d} AUC : {roc_auc_score(valid_y, test_pred_proba[valid_idx]):.6f}')\n",
    "        \n",
    "        del evalset, testinput, bst\n",
    "        gc.collect()\n",
    "\n",
    "    roc_auc_test = roc_auc_score(train_df['TARGET'], test_pred_proba)\n",
    "\n",
    "    print(f'Full AUC score {roc_auc_test:.6f}')\n",
    "\n",
    "    if save_train_prediction:\n",
    "        df_prediction = train_df[['TARGET']]\n",
    "        df_prediction['Prediction'] = test_pred_proba\n",
    "        df_prediction.to_csv('train_prediction.csv')\n",
    "        del df_prediction\n",
    "        gc.collect()\n",
    "\n",
    "    df_prediction = test_df[['TARGET']]\n",
    "    df_prediction['TARGET'] = prediction\n",
    "    df_prediction.to_csv('test_prediction.csv')\n",
    "    del df_prediction\n",
    "    gc.collect()\n",
    "    \n",
    "    return roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = dict( \n",
    "            learning_rate=0.0100664435413599,\n",
    "            colsample_bytree=0.8,\n",
    "            subsample=1,\n",
    "            max_depth=7,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=1,\n",
    "            min_child_weight=45,\n",
    "            gamma=0,\n",
    "            max_bin=256,\n",
    "            tree_method = 'gpu_hist',\n",
    "            objective='gpu:binary:logistic',\n",
    "            eval_metric='auc',\n",
    "            predictor='cpu_predictor'            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest = pd.read_csv('traintest.csv', index_col = 0)\n",
    "cols = list(traintest.columns)\n",
    "cols.remove('TARGET')\n",
    "tar = 'TARGET'\n",
    "score = cv(traintest, 5, xgb_params, stratified = True, save_train_prediction = True, n_estimators=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPU]",
   "language": "python",
   "name": "conda-env-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
